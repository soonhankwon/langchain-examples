from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_community.llms import Ollama
from langchain.prompts import ChatPromptTemplate

class State(TypedDict):
    messages: Annotated[list, add_messages]

graph_builder = StateGraph(State)
llm = Ollama(model="llama3.1:8b", temperature=0.8)

def chatbot(state: State):
    # í™í•© ìŠ¤íƒ€ì¼ì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
    chat_prompt = ChatPromptTemplate.from_messages([
        ("system", "You are a 2000s hip-hop rapper. Always respond in hip-hop style with slang, attitude and rhythm. Use emojis and hip-hop expressions."),
        ("human", "{input}")
    ])
    # ì‚¬ìš©ì ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    user_message = state["messages"][-1]
    # í”„ë¡¬í”„íŠ¸ ì‹¤í–‰
    response = chat_prompt | llm
    result = response.invoke({"input": user_message})
    
    return {"messages": [{"role": "assistant", "content": result}]}

graph_builder.add_node("chatbot", chatbot)

graph_builder.add_edge(START, "chatbot")
graph_builder.add_edge("chatbot", END)
graph = graph_builder.compile()

def stream_graph_updates(user_input: str):
    for event in graph.stream({"messages": [{"role": "user", "content": user_input}]}):
        for value in event.values():
                print("Kendrick Lamar: ", value["messages"][-1]["content"])

while True:
    try:
        user_input = input("You: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Peace out, homie! Stay fresh! ğŸ¤")
            break
        stream_graph_updates(user_input)
    except:
        # fallback if input() is not available
        user_input = "What do you know about LangGraph?"
        print("You: " + user_input)
        stream_graph_updates(user_input)
        break
